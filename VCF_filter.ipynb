{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the raw VCF and start initial filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Skip to (3) if you don't need work with the raw file ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf = pd.read_csv(\"IBM_DP10_AD_ShortNames.vcf.txt\", delimiter=\"\\t\",skiprows=301)\n",
    "vcf = vcf[vcf[\"#CHROM\"].isin([1,2,3,4,5,6,7,8,9,10])]\n",
    "vcf = vcf.drop_duplicates().reset_index(drop=True)\n",
    "vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Function to modify the vcf IDs to gene IDs based on coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The VCF was generated by calling bcftools mpileup\n",
    "geneIDs = pd.read_csv(\"gene_ids_by_region.tsv\", delimiter=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_chrom = vcf[\"#CHROM\"].iloc[0]   # keep track of the last chromosome name use, first one is 1\n",
    "geneID_list = [] # a list to keep all the gene IDs based on vcf coordinates\n",
    "count=0          # for each chromosome use the count to iterate over the rows\n",
    "\n",
    "# Trying to speed it up a bit by keeping chromosomes separate\n",
    "vcf_chrom = vcf[vcf[\"#CHROM\"]==last_chrom]     \n",
    "geneIDs_chrom = geneIDs[geneIDs[0]==last_chrom] # for both the vcf and bed-like file\n",
    "\n",
    "for v in range(len(vcf)):\n",
    "    current_chrom = vcf[\"#CHROM\"].iloc[v]\n",
    "    if current_chrom != last_chrom:\n",
    "        vcf_chrom = vcf[vcf[\"#CHROM\"] == current_chrom] # change temp files to current chromosome\n",
    "        geneIDs_chrom = geneIDs[geneIDs[0] == current_chrom]        # for both the vcf and bed-like file\n",
    "        count = 0 # restart the count to iterate over temp files\n",
    "    \n",
    "    # Finds all geneIDs with coordinates sorrounding SNP coordinates, and keeps only the first gene ID\n",
    "    vcf_pos = vcf_chrom[\"POS\"].iloc[count]\n",
    "    geneID_list.append(geneIDs_chrom[\n",
    "        (geneIDs_chrom[1] <= vcf_pos) &\n",
    "        (geneIDs_chrom[2] >= vcf_pos)].iloc[0,3])\n",
    "    last_chrom = vcf[\"#CHROM\"].iloc[v]\n",
    "    count += 1\n",
    "print(len(vcf), len(geneID_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf[\"ID\"] = geneID_list # Change the ID to to the gene names\n",
    "# sort the vcf file based on chromosome and position of SNPs\n",
    "vcf = vcf.sort_values(['#CHROM', 'POS'], ascending=[True, True]).reset_index().drop(\"index\", axis=1)\n",
    "vcf.to_csv(\"IBM_DP10_AD_ShortNames_geneIDs.vcf\", index=False, sep=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "# Manually added back the original 300 VCF header lines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load the raw VCF file containing chromsomes 1-10 and gene IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short names is the file where I converted the bam file names to the line name manually\n",
    "vcf = pd.read_csv(\"IBM_DP10_AD_ShortNames_geneIDs.vcf\", delimiter=\"\\t\")#,skiprows=301)\n",
    "vcf = vcf[vcf[\"QUAL\"] == 999.0]\n",
    "# Keep VCF metadata with the original row index for later access\n",
    "vcf_coordinates = vcf[[\"#CHROM\", \"POS\", \"ID\", \"REF\", \"ALT\", \"QUAL\", \"FILTER\", \"INFO\", \"FORMAT\"]] \n",
    "vcf = vcf.drop([\"#CHROM\", \"POS\", \"ID\", \"REF\", \"ALT\", \"QUAL\", \"FILTER\", \"INFO\", \"FORMAT\"], axis=1)\n",
    "print(len(vcf))\n",
    "vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the VCF format to multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GT(val):\n",
    "    genotype = val.split(\":\")[0]\n",
    "    if genotype == \"0/0\":\n",
    "        return \"B\"\n",
    "    elif genotype == \"1/1\":\n",
    "        return \"M\"\n",
    "    else:\n",
    "        return \"H\"\n",
    "    \n",
    "def PL(val):\n",
    "    return val.split(\":\")[1]\n",
    "\n",
    "def DP(val):\n",
    "    return int(val.split(\":\")[2])\n",
    "\n",
    "def AD(val):\n",
    "    return val.split(\":\")[3]\n",
    "\n",
    "def AD_B73(val):\n",
    "    return int(val.split(\",\")[0])\n",
    "def AD_Mo17(val):\n",
    "    return int(val.split(\",\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTdf = vcf.applymap(GT)\n",
    "PLdf = vcf.applymap(PL)\n",
    "DPdf = vcf.applymap(DP)\n",
    "ADdf = vcf.applymap(AD)\n",
    "Bdf  = ADdf.applymap(AD_B73)\n",
    "Mdf  = ADdf.applymap(AD_Mo17)\n",
    "print(len(vcf), len(GTdf), len(PLdf), len(DPdf), len(ADdf), len(Bdf), len(Mdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Apply a minimal DP filter and remove SNPs that don't match parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP_filter(val):\n",
    "    # For each value, if read depth < 10 return np.NaN\n",
    "    if val < 10:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "DPdf = DPdf.applymap(DP_filter)\n",
    "# thresh=N requires that a column has at least N non-NaNs to survive.\n",
    "DPdf = DPdf.dropna(thresh = 10, axis = 0) \n",
    "print(\"After filtering:\", len(DPdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter sites that don't match the parent inbred lines\n",
    "GTdf = GTdf[GTdf[\"B73\"]==\"B\"]\n",
    "GTdf = GTdf[GTdf[\"Mo17\"]==\"M\"]\n",
    "print(\"After filtering:\", len(GTdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows that made it through both previous filtering\n",
    "intersect = DPdf.index.intersection(GTdf.index)\n",
    "vcf_coordinates  = vcf_coordinates.loc[intersect]\n",
    "GTdf = GTdf.loc[intersect]\n",
    "DPdf = DPdf.loc[intersect]\n",
    "Bdf  = Bdf.loc[intersect]\n",
    "Mdf  = Mdf.loc[intersect]\n",
    "print(len(vcf_coordinates), len(GTdf), len(DPdf), len(Bdf), len(Mdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Filter SNPs based on gene ID groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTdf2 = GTdf.copy()\n",
    "GTdf2.index = list(vcf_coordinates[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the most common genotype as a string (B,M,H,N)\n",
    "# If two genotypes are equally common it returns a list of them\n",
    "GTgrouped = GTdf2.groupby(GTdf2.index).agg(pd.Series.mode)\n",
    "print(len(GTgrouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't seem to be necessary but I would keep it just in case some of the filtering parameters\n",
    "# generate different variations of SNP calls that should probably be ignored if not relatively certain\n",
    "def list_to_NA(val):\n",
    "    # if the previous mode function returns a numpy.ndarray list call the allele as np.NaN\n",
    "    # All alleles should either that list or \"B\", \"M\", \"H\" so it works\n",
    "    if type(val) != str:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "GTgrouped = GTgrouped.applymap(list_to_NA)\n",
    "GTgrouped = GTgrouped.dropna(thresh = 10, axis = 0) # if row has more less than thresh np.NaNs then drop it\n",
    "# There are no column with at least 10 non-NaN values\n",
    "print(len(GTgrouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_coordinates = vcf_coordinates[vcf_coordinates[\"ID\"].isin(GTgrouped.index)]\n",
    "GTdf = GTdf.loc[vcf_coordinates.index]\n",
    "Bdf  = Bdf.loc[vcf_coordinates.index]\n",
    "Mdf  = Mdf.loc[vcf_coordinates.index]\n",
    "print(len(vcf_coordinates), len(GTdf), len(Bdf), len(Mdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous step was the last that required exact numerical index\n",
    "# Now we can add the mapped gene IDs to the ID column and index columns\n",
    "# Note that this removes the original index mapping\n",
    "GTdf.index = list(vcf_coordinates[\"ID\"])\n",
    "Bdf.index  = list(vcf_coordinates[\"ID\"])\n",
    "Mdf.index  = list(vcf_coordinates[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allele_comparer(row):\n",
    "    # This function is useful to make the box-plot figure to check the correctness of the grouped genotype file\n",
    "    # since the grouped genotypes will not always match the the individual SNPs in the filtered SNP genotype file\n",
    "    # If genotypes match cell returns True and if it doesn't match it returns False\n",
    "    # In other words - this df specifies which cells were used and not used to call the grouped genotpye\n",
    "    return(row==GTgrouped.loc[row.name])\n",
    "compare_GT = GTdf.apply(allele_comparer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder it, I am not sure why it was disordered but it makes the next cell break\n",
    "# As of CPython/PyPy 3.6 (and as a language guarantee in 3.7), plain dict is insertion ordered\n",
    "# https://stackoverflow.com/questions/480214/how-do-you-remove-duplicates-from-a-list-whilst-preserving-order\n",
    "# Might not work on older python versions but the link has alternative options\n",
    "GTgrouped = GTgrouped.loc[list(dict.fromkeys(compare_GT.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By converting to 0,1 (astype(int)) I can multiple with allele count and keep the count if True\n",
    "compare_GT = compare_GT.astype(int)\n",
    "compare_Bdf = compare_GT * Bdf\n",
    "compare_Mdf = compare_GT * Mdf\n",
    "print(len(GTdf), len(compare_GT), len(Bdf), len(compare_Mdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. QC results by comparing predicted SNPs to reference SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that I have the correct counts I want to separate them based on called and alternative counts\n",
    "# This is done to make a box-plot as a quality control proof of concept to compare between all\n",
    "def rfc(row, rdf, allele):\n",
    "    # reference count function\n",
    "    # rdf: reference data frame\n",
    "    # al: reference allele to check for \n",
    "    return(rdf.loc[row.name][row==allele])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52677165/how-to-pad-pandas-dataframe-column-with-different-sizes-with-nan-values\n",
    "def pad_dict_list(dict_list, padel=\"\"):\n",
    "    lmax = 0\n",
    "    for lname in dict_list.keys():\n",
    "        lmax = max(lmax, len(dict_list[lname]))\n",
    "    for lname in dict_list.keys():\n",
    "        ll = len(dict_list[lname])\n",
    "        if  ll < lmax:\n",
    "            dict_list[lname] += [padel] * (lmax - ll)\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACd = {\"B73_B73\":  [x for x in fFAC.apply(rfc, rdf=B_counts, allele=\"B\", axis=1).to_numpy().ravel() if not pd.isnull(x)],\n",
    "        \"B73_Mo17\": [x for x in fFAC.apply(rfc, rdf=B_counts, allele=\"M\", axis=1).to_numpy().ravel() if not pd.isnull(x)],\n",
    "        \"Mo17_B73\":  [x for x in fFAC.apply(rfc, rdf=M_counts, allele=\"B\", axis=1).to_numpy().ravel() if not pd.isnull(x)],\n",
    "        \"Mo17_Mo17\":  [x for x in fFAC.apply(rfc, rdf=M_counts, allele=\"M\", axis=1).to_numpy().ravel() if not pd.isnull(x)],\n",
    "        \"Het_B73\":  [x for x in fFAC.apply(rfc, rdf=B_counts, allele=\"H\", axis=1).to_numpy().ravel() if not pd.isnull(x)],\n",
    "        \"Het_Mo17\":  [x for x in fFAC.apply(rfc, rdf=M_counts, allele=\"H\", axis=1).to_numpy().ravel() if not pd.isnull(x)]}\n",
    "FACd = pad_dict_list(FACd)\n",
    "pd.DataFrame(FACd).to_csv(\"box_plot_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Save the final IBM map as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder it (As of CPython/PyPy 3.6 (and as a language guarantee in 3.7), plain dict is insertion ordered)\n",
    "# https://stackoverflow.com/questions/480214/how-do-you-remove-duplicates-from-a-list-whilst-preserving-order\n",
    "GTgrouped2 = GTgrouped.loc[list(dict.fromkeys(compare_GT.index))]\n",
    "GTgrouped2 = GTgrouped2.fillna(\"N\")\n",
    "\n",
    "temp = vcf_coordinates.loc[vcf_coordinates.groupby('ID').POS.idxmin()]\n",
    "temp = temp.sort_values(['#CHROM', 'POS'], ascending=[True, True]).reset_index().drop(\"index\", axis=1)\n",
    "temp = temp[[\"ID\", \"#CHROM\", \"POS\"]]\n",
    "temp = temp.set_index([\"ID\"])\n",
    "temp.index.name = None\n",
    "temp.join(GTgrouped2).to_csv(\"210417 - IBM SNP Map.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
